---
title: "Data cleaning"
author: Eric Torres, ...
format:
  html:
    embed-resources: true
editor: visual
---

### 1. Load packages

```{r}
#| message: false 
#| echo: false
rm(list=ls())
library(tidyverse) 
library(readr)
```

## 2. Read data

```{r}
metadata_df <- read.table('../data/01_data_metadata.tsv', header=TRUE, sep='\t')
head(metadata_df)
```

We are going to check if there are missing values (NA):

```{r}
na_check <- anyNA(metadata_df)
na_check
```

A dataset is tidy when:

-   Each variable is a column

-   Each observation is a row

-   Each value is a cell

In the dataset we are working with, there are columns (`OTU0`- `OTU-6695`) in which the column names are one variable (`OTU`) and the cell values are another variable (`rel_abundance`). To do some tidying, we are going to use `pivot_longer()`:

```{r}
metadata_df <- metadata_df |> 
  pivot_longer(
    cols = starts_with("OTU"), 
    names_to = "OTU", 
    values_to = "rel_abundance"
  )

dim(metadata_df)
```

As a result, we get a dataframe of $N = 4,519,800$ !

It is clear that with such a long dataset, there must be some filtering by a threshoold. Before that, we can replace the numeric codes with descriptive labels. This includes variables such as Sex or Diet. To do so, we need the dictionary dataframe:

```{r}
dictionary_df <- read.table('../data/01_data_dictionary.tsv', header=TRUE, sep='\t')
```

It is clear that the primary key of `metadata_df` is a combination of all the columns. We can add a surrogate key for clearly identifying each observation.
