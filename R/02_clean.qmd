---
title: "Data cleaning"
author: Eric Torres, ...
format:
  html:
    embed-resources: true
editor: visual
---

### 1. Load packages

```{r}
#| message: false 
#| echo: false
rm(list=ls())
library(tidyverse) 
library(readr)
```

## 2. Read data

```{r}
metadata_df <- read.table('../data/01_data_metadata.tsv', header=TRUE, sep='\t')
head(metadata_df)
```

We are going to check if there are missing values (NA):

```{r}
na_check <- anyNA(metadata_df)
na_check
```

Is the value relative abundance? It is, as the total value of each row is 1.

```{r}
otu_columns <- select(metadata_df, starts_with("OTU"))
row_sums <- rowSums(otu_columns)
summary(row_sums)
```

A dataset is tidy when:

-   Each variable is a column

-   Each observation is a row

-   Each value is a cell

In the dataset we are working with, there are columns (`OTU0`- `OTU-6695`) in which the column names are one variable (`OTU`) and the cell values are another variable (`rel_abundance`). To do some tidying, we are going to use `pivot_longer()`:

```{r}
metadata_df_long <- metadata_df |> 
  pivot_longer(
    cols = starts_with("OTU"), 
    names_to = "OTU", 
    values_to = "rel_abundance"
  )

dim(metadata_df_long)
```

As a result, we get a dataframe of $N = 4,519,800$ !

It is clear that with such a long dataset, there must be some filtering by a threshoold. Before that, we can replace the numeric codes with descriptive labels. This includes variables such as Sex or Diet. To do so, we need the dictionary dataframe:

```{r}
dictionary_df <- read.table('../data/01_data_dictionary.tsv', header=FALSE, sep='\t')
```

```{r}
head(dictionary_df)
```

```{r}
dictionary_long <- dictionary_df |> 
  mutate(Column = ifelse(grepl("^[A-Za-z]", V1), V1, NA)) |> 
  fill(Column, .direction = "down") |> 
  filter(!is.na(V2)) |> 
  filter(!V1 == Column) |> 
  rename(Value = V1, Label = V2) |> 
  select(Column, Value, Label)
```

```{r}
dictionary_long
```

As the dataset still contains a large number of rows, the process is taking a long time. Therefore, I created a subset with only a thousand rows and performed the label substitution to verify if the code works. It does! Once we finalize the dataset, we can apply the changes to the entire data and create the new dataset `metadata_df_long_label`.

```{r}
metadata_mil <- metadata_df_long[1:1000,]
dim(metadata_mil)
```

```{r}
columns_to_replace <- unique(dictionary_long$Column)

for (col in columns_to_replace) {
  column_dict <- dictionary_long |> filter(Column == col)
    
  # Sustituir los valores en la columna principal
  metadata_mil[[col]] <- sapply(metadata_mil[[col]], function(x) {
   label <- column_dict |> filter(Value == x) |> pull(Label)
    if (length(label) > 0) label else x # Reemplazar si hay etiqueta, sino mantener original
  })
}
```

```{r}
metadata_mil
```

It is clear that the primary key of `metadata_df` is a combination of all the columns. We can add a surrogate key for clearly identifying each observation.
