---
title: "Data cleaning"
author: Eric Torres, Lucía de Lamadrid, Konstantina Gkopi, Elena Iriondo and Jorge Santiago
format:
  html:
    embed-resources: true
editor: visual
---

### 1. Load packages

```{r}
#| message: false 
library(tidyverse) 
library(readr)
```

### 2. Read data

```{r}
# Read the data
metadata_df <- read_tsv(file = str_c(data_folder, '/01_data_metadata.tsv'))

# Check the structure of the data
head(metadata_df)
```

```{r}
metadata_df |> 
  summarise(
    rows = n(),
    columns = ncol(metadata_df)
  )
```

The original dataset has dimensions $N = 675$ and $M = 6702$.

### 3. Data cleaning

As the dataset lacks of an identifier which can act as primary key, we introduce a numeric surrogate key using the row number (SampleID):

```{r}

#| message: false 
metadata_df <- metadata_df |>
  mutate(SampleID = row_number()) |> 
  relocate(SampleID, 
           .before = everything())  # Move SampleID to the first position
#head(metadata_df)
```

We check the existence of missing values:

```{r}
metadata_df |>  
  summarise(total_na = sum(is.na(metadata_df)))
```

Although it seems highly improbable (due to the large number of columns), we should also check if there duplicate rows:

```{r}
metadata_df |> 
  group_by(SampleID) |> 
  count(SampleID, 
        sort = TRUE) |> 
  filter(n > 1)
```

There are no NA values nor repeated observations.

To check that the values of the columns that start with 'OTU' are relative abundances, we can verify that the sum of all the rows has to be 1 for each OTU:

```{r}
otu_columns <- select(metadata_df, 
                      starts_with("OTU"))
row_sums <- rowSums(otu_columns)
summary(row_sums)
```

Columns *Data*, *Source*, *Donor*, *Collection* and *Sex* are discrete, nominal values. On the other hand, the columns with the relative abundances of the OTUs are continuous. As all of them represent the same concept, the ranges are the same. Consequently, it is not necessary to perform data normalization.

A dataset is tidy when:

-   Each variable is a column

-   Each observation is a row

-   Each value is a cell

In the dataset we are working with, there are columns (`OTU0`- `OTU-6695`) in which the column names are in reality one variable (`OTU`) and the cell values are another variable (`rel_abundance`). To do some tidying, we are going to use `pivot_longer()`:

```{r}
metadata_df_long <- metadata_df |> 
  pivot_longer(
    cols = starts_with("OTU"), 
    names_to = "OTU", 
    values_to = "rel_abundance"
  )

metadata_df_long |>  
    summarise(rows = n())
```

As a result, we get a dataframe of $N = 4,519,800$ !

**Exploring OTU Abundance Distributions and Determining Filtering Thresholds**

To reduce the size of the dataset from the original $N = 4,519,800$ rows and focus on meaningful OTUs, we apply filtering to remove low-abundance and negligible contributors.

We calculated the mean relative abundance of each OTU, ranked them in descending order, computed their cumulative contribution to total abundance, and plotted a cumulative contribution curve to identify key OTUs contributing significantly to the microbiome.

```{r}
# Calculate cumulative contribution
cumulative_otus <- metadata_df_long |>
  group_by(OTU) |>
  summarize(mean_abundance = mean(rel_abundance)) |>
  arrange(desc(mean_abundance)) |>
  mutate(cumulative_abundance = cumsum(mean_abundance) / sum(mean_abundance))

head(cumulative_otus)
```

```{r}
# Plot cumulative contribution
ggplot(
  data = cumulative_otus, 
  mapping = aes(x = reorder(OTU, -mean_abundance), 
                y = cumulative_abundance, 
                group = 1)
  ) +
  geom_line() +
  geom_hline(yintercept = 0.95, 
             linetype = "dashed", 
             color = "red") +
  geom_hline(yintercept = 0, 
             color = "black", 
             linetype = "solid") +   # Add x-axis
  geom_vline(xintercept = 0, 
             color = "black", 
             linetype = "solid") +   # Add y-axis
  labs(title = "Cumulative Contribution of OTUs", 
       x = "OTU (Ranked by Abundance)", 
       y = "Cumulative Abundance") +  
theme(axis.text.x = element_blank(), 
      axis.ticks.x = element_blank()
)
```

From the plot above, we can see that a little fraction of all the OTUs contribute to the most relative abundance, whilst a large number of them hardly add any value to the cumulative abundance. Consequently, keeping the OTUs that made up until 95% of all the cumulative abundance is a good filter: we can reduce notably the dimensions of the dataset, while we don't lose information biologically meaningful.

Note: we are doing an assumption that the most abundant OTUs are the ones with the biggest biological importance. This is not always true, like the case of keystone species, which exert big influence despite their low abundance.

summarise(rows = n())

```{r}
# Filter OTUs contributing to 95% cumulative abundance
otus_to_keep <- cumulative_otus |>
  filter(cumulative_abundance <= 0.95) |>
  pull(OTU)

# Filter the metadata to retain only these OTUs
filtered_metadata <- metadata_df_long |>
  filter(OTU %in% otus_to_keep) 

filtered_metadata |>  
  summarise(rows = n())
```

As a result, we get a data frame of $N = 264,600$ !

```{r}
# Number of OTUs before filtering
n_total_otus <- metadata_df_long |> 
  pull(OTU) |> 
  n_distinct()

# Number of OTUs after filtering
n_filtered_otus <- filtered_metadata |> 
  pull(OTU) |> 
  n_distinct()

# Print results
cat("Number of OTUs before filtering:", n_total_otus, "\n")
cat("Number of OTUs after filtering:", n_filtered_otus, "\n")
cat("Number of OTUs removed:", n_total_otus - n_filtered_otus, "\n")
cat("Percentage of OTUs removed:", (n_total_otus - n_filtered_otus) * 100 / n_total_otus, "% \n")
```

As a result of the filtering, we have narrowed down the number of OTUs from **6,696 OTUs to 392**, **6,304 OTUs** were removed.

We check the distribution of OTU relative abundances to understand the range and frequency of abundance values after having filter them. To get a good 'visualisation resolution', we use a log-scale.

```{r}
# Distribution of OTU relative abundances
ggplot(
  data = filtered_metadata, 
  mapping = aes(x = rel_abundance)
  ) +
  geom_histogram(bins = 500, 
                 fill = "skyblue", 
                 alpha = 0.7) +
  scale_x_log10() +
  labs(title = "Distribution of OTU relative abundances", 
       x = "Relative Abundance (Log scale)", 
       y = "Frequency") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5))
```

From the plot above, we can apply a stricter filter because the distribution shows a large number of OTUs with extremely low relative abundances.

```{r}
abundance_threshold <- 1e-6
# Apply the threshold to filter OTUs
filtered_metadata_stricter <- filtered_metadata |>
  filter(rel_abundance >= abundance_threshold)

filtered_metadata_stricter |> 
  summarise(rows = n())
```

As a result, we get a data frame of $N = 65,938$ !

```{r}
# Plot the distribution of relative abundances after stricter filtering
ggplot(
  data = filtered_metadata_stricter, 
  mapping = aes(x = rel_abundance)
  ) +
  geom_histogram(bins = 50, 
                 fill = "skyblue", 
                 alpha = 0.7) +
  scale_x_log10() +
  labs(title = "Distribution of OTU relative abundances", 
       x = "Relative Abundance (Log scale)", 
       y = "Frequency") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))
```

Finally, we can replace the numeric codes with descriptive labels. This includes variables such as Sex or Diet. To do so, we need the equivalences provided by the dictionary dataframe:

```{r}
filtered_metadata_stricter_label <- filtered_metadata_stricter |> 
  mutate(Diet = case_when(Diet == 0 ~ "LFPP",
                          Diet == 1 ~ "Western",
                          Diet == 2 ~ "CARBR",
                          Diet == 3 ~ "FATR",
                          Diet == 4 ~ "Suckling",
                          Diet == 5 ~ "Human")) |> 
  mutate(Source = case_when(Source == 0 ~ "Cecum1",
                          Source == 1 ~ "Cecum2", 
                          Source == 2 ~ "Colon1", 
                          Source == 3 ~ "Colon2", 
                          Source == 4 ~ "Feces",
                          Source == 5 ~ "SI1",
                          Source == 6 ~ "SI13", 
                          Source == 7 ~ "SI15", 
                          Source == 8 ~ "SI2", 
                          Source == 9 ~ "SI5",
                          Source == 10 ~ "SI9", 
                          Source == 11 ~ "Stomach", 
                          Source == 12 ~ "Cecum")) |> 
  mutate(Donor = case_when(Donor == 0 ~ "HMouseLFPP",
                          Donor == 1 ~ "CONVR", 
                          Donor == 2 ~ "Human", 
                          Donor == 3 ~ "Fresh", 
                          Donor == 4 ~ "Frozen",
                          Donor == 5 ~ "HMouseWestern", 
                          Donor == 6 ~ "CONVD")) |> 
  mutate(CollectionMet = case_when(CollectionMet == 0 ~ "Contents",
                                   CollectionMet == 1 ~ "Scraping")) |> 
  mutate(Sex = case_when(Sex == 0 ~ "Male",
                         Sex == 1 ~ "Female")) 
head(filtered_metadata_stricter_label)
```

Some subsequent analyses will require us to use a wide dataset:

```{r}
filtered_metadata_wider <- filtered_metadata_stricter_label |> 
  pivot_wider(
    names_from = OTU,               
    values_from = rel_abundance,    
  )
  
head(filtered_metadata_wider)
```

Our dataset is now tidy! Let’s save the results.

```{r}
write.table(
  filtered_metadata_stricter, 
  "../data/02_metadata_long_filtered.tsv", 
  sep = "\t", 
  quote = FALSE
)

write.table(
  filtered_metadata_stricter_label, 
  "../data/02_metadata_long_filtered_label.tsv", 
  sep = "\t", 
  quote = FALSE
)

write.table(
  filtered_metadata_wider, 
  "../data/02_metadata_wide_filtered_label.tsv", 
  sep = "\t", 
  quote = FALSE
)
```
